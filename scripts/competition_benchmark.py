# -*- coding: utf-8 -*-
"""
=============================================================================
ã€æ—ºå®ç§‘å­¸ç / ç§‘å±•å°ˆç”¨ã€‘è¤‡åˆå¼ AI å°æ¯”å¯¦é©—è‡ªå‹•åŒ–å·¥å…·ï¼ˆ3Ã—3 è¨­è¨ˆï¼‰
=============================================================================

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ç¨‹å¼åç¨±: competition_benchmark.py                                        â•‘
â•‘  ç ”ç©¶ä¸»é¡Œ: è¤‡åˆå¼ AI æ¶æ§‹é™ä½æ•¸å­¸é¡Œåº«ç”Ÿæˆæˆæœ¬ä¹‹ç ”ç©¶                          â•‘
â•‘  ç”¨é€”åˆ†é¡: å¤§è¦æ¨¡å°æ¯”å¯¦é©—åŸ·è¡Œå™¨ / é‡åŒ–æ•¸æ“šæ”¶é›†å·¥å…·                          â•‘
â•‘  å¯¦é©—è¨­è¨ˆ: 3Ã—3 å®Œå…¨å› å­è¨­è¨ˆï¼ˆFull Factorial Designï¼‰                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ã€ç ”ç©¶æ ¸å¿ƒå•é¡Œã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€Œèƒ½å¦é€éè‡ªå‹•ä¿®å¾©æ©Ÿåˆ¶ï¼ˆActive Healerï¼‰ï¼Œä½¿å°å‹ Local AIï¼ˆ14Bï¼‰
 é”åˆ°å¤§å‹ Cloud AIï¼ˆGemini Proï¼‰çš„ç¨‹å¼ç”Ÿæˆè³ªé‡ï¼Ÿã€

ã€3Ã—3 å¯¦é©—è¨­è¨ˆã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
å› å­ 1: æ¨¡å‹å¤§å°ï¼ˆModel Sizeï¼‰
  - 7B:  Qwen 2.5-Coder 7Bï¼ˆæœ¬åœ°å°æ¨¡å‹ï¼‰
  - 14B: Qwen 2.5-Coder 14Bï¼ˆæœ¬åœ°ä¸­æ¨¡å‹ï¼‰
  - Cloud: Gemini Proï¼ˆé›²ç«¯å¤§æ¨¡å‹ï¼‰

å› å­ 2: Prompt ç­–ç•¥ï¼ˆPrompt Strategyï¼‰
  - Level 1: ç›´è¦º Promptï¼ˆBare Promptï¼‰
  - Level 2: MASTER_SPECï¼ˆçµæ§‹åŒ–è¦æ ¼ï¼‰
  - Level 3: MASTER_SPEC + Active Healerï¼ˆè¦æ ¼ + ä¿®å¾©ï¼‰

å¯¦é©—çŸ©é™£ï¼ˆ9 çµ„ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        â”‚   Level 1   â”‚   Level 2   â”‚   Level 3   â”‚
â”‚        â”‚ (Bare)      â”‚ (SPEC)      â”‚ (SPEC+Heal) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 7B     â”‚ A1 âŒ       â”‚ A2 âš ï¸        â”‚ A3 âœ…       â”‚
â”‚ 14B    â”‚ B1 âŒ       â”‚ B2 âš™ï¸        â”‚ B3 ğŸ†       â”‚
â”‚ Cloud  â”‚ C1 âš ï¸        â”‚ C2 âœ…       â”‚ C3 ğŸ”       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ã€æ ¸å¿ƒå‡è¨­ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
H1: Healer å°å°æ¨¡å‹å¹«åŠ©æ›´å¤§ï¼ˆäº¤äº’ä½œç”¨æ•ˆæ‡‰ï¼‰
H2: B3ï¼ˆ14B + SPEC + Healerï¼‰â‰ˆ C2ï¼ˆCloud + SPECï¼‰
H3: B3 æˆæœ¬åƒ… C2 çš„ 2%ï¼ˆ$0.001 vs $0.05ï¼‰
H4: Active Healer å¯æå‡èªæ³•æ­£ç¢ºç‡ 30-40%ï¼ˆ7B: 30% â†’ 80%ï¼‰

ã€æœ¬ç¨‹å¼çš„ç›®çš„ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1ï¸âƒ£  è‡ªå‹•åŒ–åŸ·è¡Œ 9 çµ„å°æ¯”å¯¦é©—ï¼ˆæ¯çµ„ 100+ æ¬¡æ¸¬è©¦ï¼‰
2ï¸âƒ£  æ”¶é›†é‡åŒ–æ•¸æ“šï¼ˆèªæ³•ç‡ã€é‚è¼¯ç‡ã€æˆæœ¬ã€é€Ÿåº¦ã€ä¿®å¾©æ¬¡æ•¸ï¼‰
3ï¸âƒ£  ç”Ÿæˆå¯¦é©—å ±å‘Šï¼ˆCSV æ ¼å¼ï¼Œå¯ç›´æ¥ç”¨æ–¼çµ±è¨ˆåˆ†æï¼‰
4ï¸âƒ£  è¨˜éŒ„åˆ°è³‡æ–™åº«ï¼ˆexperiment_log è¡¨ï¼Œä¾›å¾ŒçºŒåˆ†æï¼‰
5ï¸âƒ£  æ”¯æ´é›™å› å­ ANOVA å’Œäº¤äº’ä½œç”¨æª¢é©—
  - é æœŸèªæ³•æ­£ç¢ºç‡: 95%
  - é æœŸé‚è¼¯æ­£ç¢ºç‡: 90%

ã€æœ¬ç¨‹å¼çš„ç›®çš„ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1ï¸âƒ£  è‡ªå‹•åŒ–åŸ·è¡Œå››çµ„å°æ¯”å¯¦é©—ï¼ˆæ¯çµ„ 100+ æ¬¡æ¸¬è©¦ï¼‰
2ï¸âƒ£  æ”¶é›†é‡åŒ–æ•¸æ“šï¼ˆèªæ³•ç‡ã€é‚è¼¯ç‡ã€æˆæœ¬ã€é€Ÿåº¦ã€ä¿®å¾©æ¬¡æ•¸ï¼‰
3ï¸âƒ£  ç”Ÿæˆå¯¦é©—å ±å‘Šï¼ˆCSV æ ¼å¼ï¼Œå¯ç›´æ¥ç”¨æ–¼çµ±è¨ˆåˆ†æï¼‰
4ï¸âƒ£  è¨˜éŒ„åˆ°è³‡æ–™åº«ï¼ˆexperiment_log è¡¨ï¼Œä¾›å¾ŒçºŒåˆ†æï¼‰

ã€ä¸»è¦åŠŸèƒ½ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ¨ åŠŸèƒ½ 1: å¯¦é©—æµç¨‹è‡ªå‹•åŒ–
   - è‡ªå‹•ç”Ÿæˆ MASTER_SPECï¼ˆArchitect éšæ®µï¼‰
   - è‡ªå‹•ç”Ÿæˆä»£ç¢¼ï¼ˆCoder éšæ®µï¼‰
   - è‡ªå‹•åŸ·è¡Œä¿®å¾©ï¼ˆHealer éšæ®µï¼Œå¦‚æœå•Ÿç”¨ï¼‰
   - è‡ªå‹•é©—è­‰çµæœï¼ˆèªæ³•æª¢æŸ¥ + é‚è¼¯æª¢æŸ¥ï¼‰

âœ¨ åŠŸèƒ½ 2: æ•¸æ“šæ”¶é›†èˆ‡è¨˜éŒ„
   - è¨˜éŒ„æ¯æ¬¡å¯¦é©—çš„è©³ç´°æ•¸æ“šï¼ˆæ™‚é–“ã€Tokenã€éŒ¯èª¤ã€ä¿®å¾©ï¼‰
   - å³æ™‚ä¿å­˜ï¼ˆé˜²æ­¢ä¸­é€”ä¸­æ–·ï¼‰
   - é›™é‡è¨˜éŒ„ï¼ˆCSV æ–‡ä»¶ + è³‡æ–™åº«ï¼‰

âœ¨ åŠŸèƒ½ 3: çµ±è¨ˆåˆ†æèˆ‡å ±å‘Š
   - è‡ªå‹•è¨ˆç®—å„çµ„çš„æˆåŠŸç‡ã€æˆæœ¬ã€è³ªé‡/æˆæœ¬æ¯”
   - ç”Ÿæˆå°æ¯”è¡¨æ ¼ï¼ˆé©åˆç›´æ¥è²¼åˆ°è«–æ–‡æˆ– PPTï¼‰
   - è¼¸å‡ºè©³ç´°æ—¥èªŒï¼ˆæ¯æ¬¡å¯¦é©—çš„å®Œæ•´è¨˜éŒ„ï¼‰

ã€è©•ä¼°æŒ‡æ¨™ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
1. **èªæ³•æ­£ç¢ºç‡** = AST Parse æˆåŠŸæ¬¡æ•¸ / ç¸½å¯¦é©—æ¬¡æ•¸
2. **é‚è¼¯æ­£ç¢ºç‡** = Dynamic Sampling é€šéæ¬¡æ•¸ / ç¸½å¯¦é©—æ¬¡æ•¸
3. **ä¿®å¾©æˆåŠŸç‡** = ä¿®å¾©å¾Œé€šéæ¬¡æ•¸ / åŸå§‹éŒ¯èª¤æ¬¡æ•¸
4. **è³ªé‡/æˆæœ¬æ¯”** = (é‚è¼¯æ­£ç¢ºç‡ / æˆæœ¬) Ã— 100
5. **å¹³å‡ç”Ÿæˆæ™‚é–“** = ç¸½ç”Ÿæˆæ™‚é–“ / å¯¦é©—æ¬¡æ•¸

ã€ä½¿ç”¨æ–¹å¼ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ–¹å¼ 1 (å®Œæ•´å¯¦é©— - éœ€æ™‚æ•¸å°æ™‚):
  $ python scripts/competition_benchmark.py
  â†’ åŸ·è¡Œæ‰€æœ‰æŠ€èƒ½ Ã— æ‰€æœ‰çµ„åˆ¥ Ã— 10 æ¬¡é‡è¤‡

æ–¹å¼ 2 (å°è¦æ¨¡æ¸¬è©¦ - æ¨è–¦å…ˆåŸ·è¡Œ):
  1. ç·¨è¼¯æœ¬æ–‡ä»¶ Line 90-95
  2. ä¿®æ”¹ "test_skills" ç‚º 2-3 å€‹æŠ€èƒ½
  3. ä¿®æ”¹ "trials_per_skill" ç‚º 3
  4. åŸ·è¡Œç¨‹å¼

è¼¸å‡ºçµæœ:
  - CSV æ‘˜è¦: reports/competition_experiments/experiment_summary_YYYYMMDD.csv
  - CSV è©³ç´°: reports/competition_experiments/experiment_details_YYYYMMDD.csv
  - è³‡æ–™åº«: experiment_log è¡¨ï¼ˆå¯ç”¨ SQL æŸ¥è©¢ï¼‰

ã€è³‡æ–™åº«æ•´åˆã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æ¯æ¬¡å¯¦é©—è‡ªå‹•è¨˜éŒ„åˆ° experiment_log è¡¨ï¼ŒåŒ…å«ï¼š
  - å¯¦é©—è­˜åˆ¥ï¼šskill_id, experiment_batch, experiment_group
  - AI é…ç½®ï¼šmodel_name, model_size_class, prompt_level
  - æˆæœ¬è¿½è¹¤ï¼šprompt_tokens, completion_tokens, total_tokens
  - è³ªé‡è©•ä¼°ï¼šis_success, is_executable, score_syntax, score_math
  - ä¿®å¾©çµ±è¨ˆï¼šregex_fix_count, logic_fix_count, ast_repair_count
  - ä»£ç¢¼ä¿å­˜ï¼šraw_response, final_code

æŸ¥è©¢ç¯„ä¾‹:
  SELECT experiment_group, AVG(score_math), AVG(total_tokens)
  FROM experiment_log
  WHERE experiment_batch = '2026-01-27_full_test'
  GROUP BY experiment_group;

ã€ç‰ˆæœ¬è³‡è¨Šã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ç‰ˆæœ¬: V1.0
æ—¥æœŸ: 2026-01-27
ä½œè€…: Math AI Project Team
ç«¶è³½: æ—ºå®ç§‘å­¸ç / ä¸­å­¸ç§‘å±•
ä¾è³´: flask, sqlalchemy, ast, csv

ã€ç›¸é—œæ–‡ä»¶ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- ç ”ç©¶è¨ˆç•«: docs/ç«¶è³½æ–‡ä»¶/æ—ºå®ç§‘å­¸ç_ç ”ç©¶è¨ˆç•«.md
- å¿«é€Ÿé–‹å§‹: docs/ç«¶è³½æ–‡ä»¶/å¿«é€Ÿé–‹å§‹æŒ‡å—.md
- è³‡æ–™åº«è¨­è¨ˆ: docs/ç«¶è³½æ–‡ä»¶/è³‡æ–™åº«è¨­è¨ˆé©—è­‰å ±å‘Š.md
- å¯è¦–åŒ–å·¥å…·: scripts/visualize_healer.py

=============================================================================
"""

import os
import sys
import json
import time
import csv
from datetime import datetime
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from flask import Flask
from models import db, SkillInfo, ExperimentLog
from config import Config
from core.code_generator import auto_generate_skill_code
from core.prompt_architect import generate_v15_spec
import ast

# ==============================================================================
# å¯¦é©—é…ç½®ï¼ˆ3Ã—3 å› å­è¨­è¨ˆï¼‰
# ==============================================================================

EXPERIMENT_CONFIG = {
    # 3Ã—3 å¯¦é©—çµ„é…ç½®
    # æ©«è»¸ï¼šæ¨¡å‹å¤§å° (7B / 14B / Cloud)
    # ç¸±è»¸ï¼šPrompt ç­–ç•¥ (Bare / MASTER / MASTER+Healer)
    
    "groups": {
        # ========== 7B æ¨¡å‹ç³»åˆ— ==========
        "A1_7b_bare": {
            "name": "A1: Qwen 7B + ç›´è¦º Prompt",
            "model": "qwen2.5-coder:7b",
            "model_size_class": "7B",
            "prompt_level": "Bare",
            "use_master_spec": False,
            "healer": False,
            "cost_per_skill": 0.000
        },
        "A2_7b_master": {
            "name": "A2: Qwen 7B + MASTER_SPEC",
            "model": "qwen2.5-coder:7b",
            "model_size_class": "7B",
            "prompt_level": "Engineered",
            "use_master_spec": True,
            "healer": False,
            "cost_per_skill": 0.000
        },
        "A3_7b_healer": {
            "name": "A3: Qwen 7B + MASTER + Healer",
            "model": "qwen2.5-coder:7b",
            "model_size_class": "7B",
            "prompt_level": "Self-Healing",
            "use_master_spec": True,
            "healer": True,
            "cost_per_skill": 0.001
        },
        
        # ========== 14B æ¨¡å‹ç³»åˆ— ==========
        "B1_14b_bare": {
            "name": "B1: Qwen 14B + ç›´è¦º Prompt",
            "model": "qwen2.5-coder:14b",
            "model_size_class": "14B",
            "prompt_level": "Bare",
            "use_master_spec": False,
            "healer": False,
            "cost_per_skill": 0.000
        },
        "B2_14b_master": {
            "name": "B2: Qwen 14B + MASTER_SPEC",
            "model": "qwen2.5-coder:14b",
            "model_size_class": "14B",
            "prompt_level": "Engineered",
            "use_master_spec": True,
            "healer": False,
            "cost_per_skill": 0.000
        },
        "B3_14b_healer": {
            "name": "B3: Qwen 14B + MASTER + Healer ğŸ¯",
            "model": "qwen2.5-coder:14b",
            "model_size_class": "14B",
            "prompt_level": "Self-Healing",
            "use_master_spec": True,
            "healer": True,
            "cost_per_skill": 0.001
        },
        
        # ========== Cloud Pro ç³»åˆ— ==========
        "C1_cloud_bare": {
            "name": "C1: Gemini Pro + ç›´è¦º Prompt",
            "model": "gemini-pro",
            "model_size_class": "Cloud",
            "prompt_level": "Bare",
            "use_master_spec": False,
            "healer": False,
            "cost_per_skill": 0.030
        },
        "C2_cloud_master": {
            "name": "C2: Gemini Pro + MASTER_SPEC",
            "model": "gemini-pro",
            "model_size_class": "Cloud",
            "prompt_level": "Engineered",
            "use_master_spec": True,
            "healer": False,
            "cost_per_skill": 0.050
        },
        "C3_cloud_healer": {
            "name": "C3: Gemini Pro + MASTER + Healer",
            "model": "gemini-pro",
            "model_size_class": "Cloud",
            "prompt_level": "Self-Healing",
            "use_master_spec": True,
            "healer": True,
            "cost_per_skill": 0.050
        }
    },
    
    # æ¸¬è©¦æŠ€èƒ½åˆ—è¡¨ï¼ˆå¯æ“´å±•åˆ° 20 å€‹ï¼‰
    "test_skills": [
        "jh_æ•¸å­¸1ä¸Š_IntegerAdditionOperation",
        "jh_æ•¸å­¸1ä¸Š_IntegerSubtractionOperation",
        "jh_æ•¸å­¸1ä¸Š_MixedIntegerAdditionAndSubtraction",
        # å¯ä»¥æ·»åŠ æ›´å¤šæŠ€èƒ½é»ï¼Œç›®æ¨™ 20 å€‹
    ],
    
    # æ¯å€‹æŠ€èƒ½çš„æ¸¬è©¦æ¬¡æ•¸
    "trials_per_skill": 10,
    
    # å¯¦é©—æ‰¹æ¬¡åç¨±ï¼ˆç”¨æ–¼å€åˆ†ä¸åŒå¯¦é©—è¼ªæ¬¡ï¼‰
    "experiment_batch": f"3x3_design_{datetime.now().strftime('%Y%m%d')}",
    
    # è¼¸å‡ºç›®éŒ„
    "output_dir": "reports/competition_experiments"
}

# ==============================================================================
# å¯¦é©—åŸ·è¡Œå™¨
# ==============================================================================

class CompetitionBenchmark:
    """ç§‘å­¸ç«¶è³½å¯¦é©—åŸ·è¡Œå™¨"""
    
    def __init__(self, app):
        self.app = app
        self.results = []
        self.output_dir = Path(EXPERIMENT_CONFIG["output_dir"])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def check_syntax(self, code_str):
        """æª¢æŸ¥èªæ³•æ­£ç¢ºæ€§"""
        try:
            ast.parse(code_str)
            return True, None
        except SyntaxError as e:
            return False, str(e)
    
    def check_logic(self, skill_file_path):
        """æª¢æŸ¥é‚è¼¯æ­£ç¢ºæ€§ï¼ˆåŸ·è¡Œ generate å‡½æ•¸ï¼‰"""
        try:
            # å‹•æ…‹å°å…¥æŠ€èƒ½æ¨¡çµ„
            import importlib.util
            spec = importlib.util.spec_from_file_location("skill_module", skill_file_path)
            module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(module)
            
            # åŸ·è¡Œ 5 æ¬¡ generate
            for i in range(5):
                q, a = module.generate()
                if not q or not a:
                    return False, f"Empty output at iteration {i+1}"
            
            return True, None
        except Exception as e:
            return False, str(e)
    
    def run_single_experiment(self, skill_id, group_name, group_config):
        """åŸ·è¡Œå–®æ¬¡å¯¦é©— + å®Œæ•´è³‡æ–™åº«è¨˜éŒ„"""
        print(f"\n{'='*60}")
        print(f"Skill: {skill_id}")
        print(f"Group: {group_name} - {group_config['name']}")
        print(f"{'='*60}")
        
        start_time = time.time()
        result = {
            "skill_id": skill_id,
            "group": group_name,
            "timestamp": datetime.now().isoformat(),
            "syntax_pass": False,
            "logic_pass": False,
            "generation_time": 0,
            "cost": group_config["cost_per_skill"],
            "errors": [],
            "healer_enabled": group_config["healer"]
        }
        
        # è³‡æ–™åº«è¨˜éŒ„è®Šæ•¸
        raw_response = ""
        final_code = ""
        healing_stats = {
            "regex_fix_count": 0,
            "logic_fix_count": 0,
            "ast_repair_count": 0,
            "garbage_cleaner_count": 0,
            "eval_eliminator_count": 0
        }
        prompt_tokens = 0
        completion_tokens = 0
        spec_prompt_id = None
        
        try:
            with self.app.app_context():
                # Step 1: ç”Ÿæˆ MASTER_SPEC (Architect)
                if group_config["architect"] == "gemini":
                    print("[Architect] Using Gemini Flash...")
                    spec_result = generate_v15_spec(skill_id, model_tag="cloud_pro")
                else:
                    print("[Architect] Using Local AI...")
                    spec_result = generate_v15_spec(skill_id, model_tag="local_14b")
                
                if not spec_result['success']:
                    result["errors"].append(f"Architect failed: {spec_result.get('message')}")
                    self._save_experiment_log(skill_id, group_name, group_config, result, 
                                             raw_response, final_code, healing_stats, 
                                             prompt_tokens, completion_tokens, spec_prompt_id)
                    return result
                
                # å–å¾— MASTER_SPEC çš„ prompt ID
                spec_prompt_id = spec_result.get('prompt_id')
                
                # Step 2: ç”Ÿæˆä»£ç¢¼ (Coder)
                if group_config["coder"] == "gemini":
                    print("[Coder] Using Gemini Pro...")
                    coder_model = "gemini-pro"
                else:
                    print("[Coder] Using Qwen 14B...")
                    coder_model = "qwen2.5-coder:14b"
                
                # Step 3: è‡ªå‹•ç”Ÿæˆï¼ˆåŒ…å« Healerï¼‰
                gen_result = auto_generate_skill_code(
                    skill_id=skill_id,
                    model_tag=group_config.get("model_tag", "local_14b"),
                    coder_model=coder_model,
                    enable_healer=group_config["healer"]
                )
                
                result["generation_time"] = time.time() - start_time
                
                # æå–è©³ç´°ä¿¡æ¯
                raw_response = gen_result.get('raw_response', '')
                final_code = gen_result.get('final_code', '')
                healing_stats = gen_result.get('healing_stats', healing_stats)
                prompt_tokens = gen_result.get('prompt_tokens', 0)
                completion_tokens = gen_result.get('completion_tokens', 0)
                
                if not gen_result['success']:
                    result["errors"].append(f"Coder failed: {gen_result.get('message')}")
                    self._save_experiment_log(skill_id, group_name, group_config, result, 
                                             raw_response, final_code, healing_stats, 
                                             prompt_tokens, completion_tokens, spec_prompt_id)
                    return result
                
                # Step 4: èªæ³•æª¢æŸ¥
                skill_file = f"skills/{skill_id}.py"
                with open(skill_file, 'r', encoding='utf-8') as f:
                    final_code = f.read()  # æ›´æ–°ç‚ºå¯¦éš›æª”æ¡ˆå…§å®¹
                
                syntax_ok, syntax_err = self.check_syntax(final_code)
                result["syntax_pass"] = syntax_ok
                if not syntax_ok:
                    result["errors"].append(f"Syntax Error: {syntax_err}")
                    self._save_experiment_log(skill_id, group_name, group_config, result, 
                                             raw_response, final_code, healing_stats, 
                                             prompt_tokens, completion_tokens, spec_prompt_id)
                    return result
                
                # Step 5: é‚è¼¯æª¢æŸ¥
                logic_ok, logic_err = self.check_logic(skill_file)
                result["logic_pass"] = logic_ok
                if not logic_ok:
                    result["errors"].append(f"Logic Error: {logic_err}")
                
                print(f"âœ… Success! Time: {result['generation_time']:.2f}s")
                
                # æˆåŠŸå®Œæˆï¼Œè¨˜éŒ„åˆ°è³‡æ–™åº«
                self._save_experiment_log(skill_id, group_name, group_config, result, 
                                         raw_response, final_code, healing_stats, 
                                         prompt_tokens, completion_tokens, spec_prompt_id)
                
        except Exception as e:
            result["errors"].append(f"Unexpected error: {str(e)}")
            print(f"âŒ Failed: {str(e)}")
            # å³ä½¿å¤±æ•—ä¹Ÿè¨˜éŒ„
            self._save_experiment_log(skill_id, group_name, group_config, result, 
                                     raw_response, final_code, healing_stats, 
                                     prompt_tokens, completion_tokens, spec_prompt_id)
        
        return result
    
    def _save_experiment_log(self, skill_id, group_name, group_config, result, 
                             raw_response, final_code, healing_stats, 
                             prompt_tokens, completion_tokens, spec_prompt_id):
        """å„²å­˜å¯¦é©—è¨˜éŒ„åˆ°è³‡æ–™åº«"""
        try:
            log_entry = ExperimentLog(
                skill_id=skill_id,
                experiment_group=group_name,  # 'A1', 'A2', 'A3', 'B1', 'B2', 'B3', 'C1', 'C2', 'C3'
                model_name=group_config.get('coder_model', group_config.get('model', 'unknown')),
                model_size_class=group_config.get('model_size_class', 'Unknown'),
                prompt_level=group_config.get('prompt_level', 'Unknown'),
                use_master_spec=group_config.get('use_master_spec', False),
                spec_prompt_id=spec_prompt_id,
                raw_response=raw_response,
                final_code=final_code,
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens,
                total_tokens=prompt_tokens + completion_tokens,
                is_success=result['syntax_pass'] and result['logic_pass'],
                is_executable=result['syntax_pass'],
                score_syntax=1.0 if result['syntax_pass'] else 0.0,
                score_math=1.0 if result['logic_pass'] else 0.0,
                score_visual=0.0,  # æš«ä¸è©•ä¼°
                healing_duration=result['generation_time'],
                regex_fix_count=healing_stats.get('regex_fix_count', 0),
                logic_fix_count=healing_stats.get('logic_fix_count', 0),
                ast_repair_count=healing_stats.get('ast_repair_count', 0),
                garbage_cleaner_count=healing_stats.get('garbage_cleaner_count', 0),
                eval_eliminator_count=healing_stats.get('eval_eliminator_count', 0),
                sampling_success_count=healing_stats.get('sampling_success_count', 0),
                sampling_total_count=healing_stats.get('sampling_total_count', 0)
            )
            
            db.session.add(log_entry)
            db.session.commit()
            print(f"ğŸ“Š Experiment log saved: ID={log_entry.id}")
            
        except Exception as e:
            print(f"âš ï¸  Failed to save experiment log: {str(e)}")
            db.session.rollback()
    
    def run_all_experiments(self):
        """åŸ·è¡Œæ‰€æœ‰å¯¦é©—"""
        print("\n" + "="*60)
        print("ğŸ”¬ é–‹å§‹åŸ·è¡Œæ—ºå®ç§‘å­¸çå¯¦é©—")
        print("="*60)
        
        total_experiments = (
            len(EXPERIMENT_CONFIG["test_skills"]) * 
            len(EXPERIMENT_CONFIG["groups"]) * 
            EXPERIMENT_CONFIG["trials_per_skill"]
        )
        
        print(f"ğŸ“Š å¯¦é©—è¦æ¨¡:")
        print(f"   - æŠ€èƒ½æ•¸: {len(EXPERIMENT_CONFIG['test_skills'])}")
        print(f"   - å¯¦é©—çµ„æ•¸: {len(EXPERIMENT_CONFIG['groups'])}")
        print(f"   - æ¯çµ„é‡è¤‡æ¬¡æ•¸: {EXPERIMENT_CONFIG['trials_per_skill']}")
        print(f"   - ç¸½å¯¦é©—æ¬¡æ•¸: {total_experiments}")
        print()
        
        exp_count = 0
        
        for skill_id in EXPERIMENT_CONFIG["test_skills"]:
            for group_name, group_config in EXPERIMENT_CONFIG["groups"].items():
                for trial in range(EXPERIMENT_CONFIG["trials_per_skill"]):
                    exp_count += 1
                    print(f"\n[{exp_count}/{total_experiments}] Trial {trial+1}/{EXPERIMENT_CONFIG['trials_per_skill']}")
                    
                    result = self.run_single_experiment(skill_id, group_name, group_config)
                    self.results.append(result)
                    
                    # å³æ™‚ä¿å­˜çµæœï¼ˆé˜²æ­¢ä¸­é€”ä¸­æ–·ï¼‰
                    self.save_interim_results()
        
        # æœ€çµ‚åˆ†æ
        self.analyze_and_save()
    
    def save_interim_results(self):
        """å³æ™‚ä¿å­˜çµæœï¼ˆJSON æ ¼å¼ï¼‰"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        json_file = self.output_dir / f"interim_results_{timestamp}.json"
        
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
    
    def analyze_and_save(self):
        """åˆ†æçµæœä¸¦ä¿å­˜ CSV å ±å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“Š åˆ†æå¯¦é©—çµæœ")
        print("="*60)
        
        # æŒ‰çµ„åˆ¥çµ±è¨ˆ
        group_stats = {}
        for group_name in EXPERIMENT_CONFIG["groups"].keys():
            group_results = [r for r in self.results if r["group"] == group_name]
            
            total = len(group_results)
            syntax_pass = sum(1 for r in group_results if r["syntax_pass"])
            logic_pass = sum(1 for r in group_results if r["logic_pass"])
            avg_time = sum(r["generation_time"] for r in group_results) / total if total > 0 else 0
            total_cost = sum(r["cost"] for r in group_results)
            
            group_stats[group_name] = {
                "name": EXPERIMENT_CONFIG["groups"][group_name]["name"],
                "total_experiments": total,
                "syntax_pass_rate": syntax_pass / total * 100 if total > 0 else 0,
                "logic_pass_rate": logic_pass / total * 100 if total > 0 else 0,
                "avg_generation_time": avg_time,
                "total_cost": total_cost,
                "quality_cost_ratio": (logic_pass / total * 100) / (total_cost + 0.001) if total > 0 else 0
            }
        
        # æ‰“å°çµ±è¨ˆçµæœ
        print("\nğŸ“ˆ å¯¦é©—çµ„å°æ¯”:")
        print(f"{'çµ„åˆ¥':<30} {'èªæ³•é€šéç‡':<12} {'é‚è¼¯é€šéç‡':<12} {'å¹³å‡æ™‚é–“':<10} {'ç¸½æˆæœ¬':<10} {'è³ªé‡/æˆæœ¬':<12}")
        print("-" * 100)
        
        for group_name, stats in group_stats.items():
            print(f"{stats['name']:<30} "
                  f"{stats['syntax_pass_rate']:>10.1f}% "
                  f"{stats['logic_pass_rate']:>10.1f}% "
                  f"{stats['avg_generation_time']:>8.2f}s "
                  f"${stats['total_cost']:>8.2f} "
                  f"{stats['quality_cost_ratio']:>10.1f}")
        
        # ä¿å­˜ CSV
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = self.output_dir / f"experiment_summary_{timestamp}.csv"
        
        with open(csv_file, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.DictWriter(f, fieldnames=[
                'group', 'name', 'total_experiments', 'syntax_pass_rate', 
                'logic_pass_rate', 'avg_generation_time', 'total_cost', 'quality_cost_ratio'
            ])
            writer.writeheader()
            for group_name, stats in group_stats.items():
                writer.writerow({'group': group_name, **stats})
        
        # ä¿å­˜å®Œæ•´è©³ç´°çµæœ
        detailed_csv = self.output_dir / f"experiment_details_{timestamp}.csv"
        with open(detailed_csv, 'w', newline='', encoding='utf-8-sig') as f:
            if self.results:
                writer = csv.DictWriter(f, fieldnames=self.results[0].keys())
                writer.writeheader()
                writer.writerows(self.results)
        
        print(f"\nâœ… çµæœå·²ä¿å­˜:")
        print(f"   - æ‘˜è¦: {csv_file}")
        print(f"   - è©³ç´°: {detailed_csv}")

# ==============================================================================
# Main Entry
# ==============================================================================

def main():
    """ä¸»ç¨‹å¼"""
    print("=" * 60)
    print("ğŸ† æ—ºå®ç§‘å­¸ç - è¤‡åˆå¼ AI è‡ªå‹•ä¿®å¾©æ©Ÿåˆ¶å¯¦é©—")
    print("=" * 60)
    
    # å‰µå»º Flask App
    app = Flask(__name__)
    app.config.from_object(Config)
    db.init_app(app)
    
    # åŸ·è¡Œå¯¦é©—
    benchmark = CompetitionBenchmark(app)
    benchmark.run_all_experiments()
    
    print("\nğŸ‰ å¯¦é©—å®Œæˆï¼")

if __name__ == "__main__":
    main()
