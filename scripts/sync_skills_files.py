# -*- coding: utf-8 -*-
# ==============================================================================
# ID: sync_skills_files.py
# Version: V9.2.0 (Scientific Standard Edition)
# Last Updated: 2026-01-27
# Author: Math AI Research Team (Advisor & Student)
#
# [Description]:
#   æœ¬ç¨‹å¼æ˜¯ç§‘å±•å¯¦é©—çš„æ ¸å¿ƒåŸ·è¡Œæ§åˆ¶å° (Experiment Runner)ï¼Œè² è²¬é©…å‹•ã€Œè‡ªå‹•å‡ºé¡Œèˆ‡ä¿®å¾©æµæ°´ç·šã€ã€‚
#   å®ƒä¸»è¦ç”¨æ–¼åŸ·è¡Œ 3x3 çŸ©é™£å¯¦é©— (3 Model Sizes x 3 Ablation Levels)ï¼Œ
#   è—‰æ­¤é‡åŒ– AST/Regex è‡ªç™’æ©Ÿåˆ¶å¦‚ä½•æå‡å°æ¨¡å‹ (Local 14B/7B) çš„ä»£ç¢¼ç”Ÿæˆèƒ½åŠ›ã€‚
#
#   [Scientific Control Strategy]:
#   ç‚ºäº†ç¢ºä¿å¯¦é©—æ•¸æ“šå…·å‚™çµ±è¨ˆå­¸æ„ç¾©èˆ‡å¯æ¯”æ€§ï¼Œæœ¬ç¨‹å¼åœ¨åŸ·è¡Œã€Œå°ˆå®¶åˆ†å·¥æ¨¡å¼ (Mode 4)ã€æ™‚ï¼Œ
#   æ¡å–ã€Œå–®ä¸€é»ƒé‡‘æ¨™æº– (Unified Golden Standard)ã€ç­–ç•¥ï¼š
#   ç„¡è«–ç•¶å‰æ¸¬è©¦çš„æ¨¡å‹å¤§å°ç‚ºä½•ï¼Œæ¶æ§‹å¸« (Architect) éšæ®µå¼·åˆ¶ç”Ÿæˆä¸¦é–å®š 'standard_14b' è¦æ ¼æ›¸ã€‚
#   é€™ç¢ºä¿äº†æ‰€æœ‰å¯¦é©—çµ„åˆ¥ (Experimental Groups) é¢å°çš„éƒ½æ˜¯åŒä¸€ä»½æ¨™æº–é›£åº¦çš„é¡Œç›®è¦æ ¼ (Control Variable)ã€‚
#
# [Database Schema Usage]:
#   1. Read:  SkillInfo, SkillCurriculum (ç¯©é¸ç›®æ¨™æŠ€èƒ½ç¯„åœ)
#   2. Read:  SkillGenCodePrompt (è®€å– MASTER_SPEC ä¾› Coder å¯¦ä½œ)
#   3. Write: SkillInfo.gemini_prompt (æ¸…ç†èˆŠæœ‰ Prompt æ¨™è¨˜)
#   4. Write: experiment_log (é—œéµï¼è¨˜éŒ„ Token æ¶ˆè€—ã€AST ä¿®å¾©æ¬¡æ•¸ã€æˆåŠŸç‡ç­‰å¯¦é©—æ•¸æ“š)
#   5. Write: Local File System (å¯«å…¥æœ€çµ‚é€šéé©—è­‰çš„ .py æŠ€èƒ½æª”æˆ–å¤±æ•—æ¨£æœ¬)
#
# [Logic Flow]:
#   1. Range Selection    -> ä½¿ç”¨è€…ç¯©é¸èª²ç¶±/å¹´ç´š/ç« ç¯€ï¼Œé–å®šæ¸¬è©¦ç¯„åœã€‚
#   2. Gap Analysis       -> æ¯”å°è³‡æ–™åº«èˆ‡æœ¬åœ°æª”æ¡ˆï¼Œæ‰¾å‡ºç¼ºå¤±æˆ–éœ€æ›´æ–°çš„æŠ€èƒ½ã€‚
#   3. Experiment Config  -> è¨­å®š Ablation ID (1:Bare, 2:Engineered, 3:Full-Healing) èˆ‡ Model Classã€‚
#   4. Phase 1 Architect  -> (è‹¥é¸ Mode 4) å¼·åˆ¶ç”Ÿæˆæ¨™æº–è¦æ ¼æ›¸ (Tag: standard_14b)ã€‚
#   5. Phase 2 Coder      -> å‘¼å« code_generator é€²è¡Œç”Ÿæˆã€AST/Regex ä¿®å¾©èˆ‡æ²™ç›’é©—è­‰ã€‚
#   6. Data Logging       -> å°‡å®Œæ•´å¯¦é©—éç¨‹å¯«å…¥ experiment_log ä»¥ä¾›å¾ŒçºŒåˆ†æã€‚
# ==============================================================================

import sys
import os
import glob
import time
import logging
import ast # [Research] Import AST for robust parsing
from datetime import datetime
from tqdm import tqdm
from sqlalchemy import distinct

# ==============================================================================
# 1. æ™ºæ…§è·¯å¾‘è¨­å®š (è‡ªå‹•åµæ¸¬å°ˆæ¡ˆæ ¹ç›®éŒ„)
# ==============================================================================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = current_dir
while not os.path.exists(os.path.join(project_root, 'app.py')):
    parent = os.path.dirname(project_root)
    if parent == project_root:
        print("âŒ éŒ¯èª¤ï¼šç„¡æ³•å®šä½å°ˆæ¡ˆæ ¹ç›®éŒ„ (æ‰¾ä¸åˆ° app.py)")
        sys.exit(1)
    project_root = parent

if project_root not in sys.path:
    sys.path.insert(0, project_root)

from app import create_app
from models import db, SkillInfo, SkillCurriculum, TextbookExample, SkillGenCodePrompt
# [Research] Import requested functions
from core.code_generator import auto_generate_skill_code
from core.prompt_architect import generate_v15_spec
from config import Config

PROTECTED_FILES = {
    "Example_Program.py",
    "__init__.py", 
    "base_skill.py"
}

def get_user_selection(options, prompt_text):
    if not options: return None
    # [Fix] ç§»é™¤ sorted()ï¼Œä¿ç•™å¤–éƒ¨å‚³å…¥çš„æ­£ç¢ºé †åº (display_order)
    options = [o for o in options if o is not None]
    
    print(f"\n{prompt_text}")
    print("   [0] ALL (å…¨éƒ¨/è·³é)")
    for i, opt in enumerate(options, 1):
        print(f"   [{i}] {opt}")
        
    while True:
        try:
            choice = input("ğŸ‘‰ è«‹é¸æ“‡ (è¼¸å…¥æ•¸å­—): ").strip()
            if choice == '0': return None
            idx = int(choice) - 1
            if 0 <= idx < len(options): return options[idx]
            print("âŒ è¼¸å…¥ç„¡æ•ˆï¼Œè«‹é‡è©¦ã€‚")
        except ValueError:
            print("âŒ è«‹è¼¸å…¥æ•¸å­—ã€‚")

def reset_skill_prompts(skill_ids):
    """
    [Fix] ä½¿ç”¨ç©ºå­—ä¸² "" è€Œé None ä¾†æ¸…ç©º Promptã€‚
    è§£æ±º sqlite3.IntegrityError: NOT NULL constraint failed
    """
    if not skill_ids: return
    try:
        # æ³¨æ„: é€™è£¡æ˜¯æ¸…ç©º gemini_prompt æ¬„ä½ (èˆŠæ¬„ä½)ï¼Œé›–ç„¶ç¾åœ¨ä¸»è¦ç”¨ SkillGenCodePrompt è¡¨
        # ä½†ç‚ºäº†ä¿æŒç›¸å®¹æ€§ï¼Œæˆ‘å€‘é‚„æ˜¯æ¸…ä¸€ä¸‹
        SkillInfo.query.filter(SkillInfo.skill_id.in_(skill_ids)).update({SkillInfo.gemini_prompt: ""}, synchronize_session=False)
        db.session.commit()
        # åŒæ™‚ä¹Ÿå¯ä»¥è€ƒæ…®æ¸…ç©º SkillGenCodePrompt è¡¨ä¸­å°æ‡‰çš„ standard_14b è¨˜éŒ„ï¼Œå¼·åˆ¶é‡æ–°ç”Ÿæˆ
        # ä½† generate_v15_spec æœƒè‡ªå‹•è¦†è“‹ï¼Œæ‰€ä»¥ä¸å¼·åˆ¶ delete ä¹Ÿå¯ä»¥
        tqdm.write(f"ğŸ§¹ å·²æ¸…ç©º {len(skill_ids)} ç­†èˆŠè³‡æ–™æ¨™è¨˜ã€‚")
    except Exception as e:
        tqdm.write(f"âš ï¸ æ¸…ç©ºèˆŠè¦æ ¼å¤±æ•—: {e}")
        db.session.rollback()

def auto_patch_missing_functions(code_content, skill_id):
    """
    [Research Edition] ä½¿ç”¨ AST é€²è¡Œçµæ§‹åŒ–åµæ¸¬èˆ‡ä¿®å¾©
    """
    patches = []
    tree = None
    
    try:
        tree = ast.parse(code_content)
    except Exception as e:
        tqdm.write(f"âš ï¸ AST Parse Error for {skill_id}: {e}")
        pass # Continue to try raw string check if AST fails initially

    has_generate = False
    has_check = False
    generate_args = []
    
    if tree:
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if node.name == 'generate':
                    has_generate = True
                    generate_args = [a.arg for a in node.args.args]
                elif node.name == 'check':
                    has_check = True

    # 1. æª¢æŸ¥ generate é€²å…¥é»
    if not has_generate:
        # Fallback raw check
        if "def generate" not in code_content:
            # å°‹æ‰¾æ˜¯å¦æœ‰é¡ä¼¼ generate_number_line é€™æ¨£çš„è®Šé«”
            import re
            alt_gen = re.findall(r'def (generate_[a-zA-Z0-9_]+)\(', code_content)
            if alt_gen:
                patches.append(f"\n# [Auto-Fix] Alias {alt_gen[0]} to generate")
                patches.append(f"generate = {alt_gen[0]}")
            else:
                # æ³¨å…¥å¼·åŠ›èª¿åº¦å™¨
                patches.append("\n# [Auto-Fix] Injected Robust Dispatcher")
                patches.append("def generate(level=1, **kwargs): return {'question_text': 'é¡Œç›®ç”Ÿæˆå¤±æ•—(Dispatcher Missing)', 'correct_answer': 'N/A'}")
    
    elif not any(arg in ['level', 'kwargs'] for arg in generate_args):
        # å¦‚æœæœ‰ generate ä½†æ²’æœ‰åƒæ•¸ï¼Œé€™æœƒå°è‡´ crash
        code_content = code_content.replace("def generate():", "def generate(level=1, **kwargs):")

    # 2. æª¢æŸ¥ check å‡½å¼
    if not has_check and "def check" not in code_content:
        patches.append("\n# [Auto-Fix] Emergency Fallback Check")
        patches.append("def check(u, c): return {'correct': False, 'result': 'è©•åˆ†ç³»çµ±ç•°å¸¸(Check Missing)'}")

    if patches:
        tqdm.write(f"ğŸ”§ {skill_id}: Detected missing functions via AST. Applying patches.")
        return code_content + "\n" + "\n".join(patches)
    
    return code_content

def run_expert_pipeline(skill_ids, arch_model, current_model, ablation_id, model_size_class, prompt_level):
    """
    åŸ·è¡Œå®Œæ•´çš„å°ˆå®¶åˆ†å·¥æµç¨‹ (Phase 1 + Phase 2)
    [Research]: Supports Ablation Logic
    [V9.2 Update]: å¼·åˆ¶çµ±ä¸€ä½¿ç”¨ 'standard_14b' è¦æ ¼ï¼Œç¢ºä¿èˆ‡ Factory æ¨™æº–ä¸€è‡´ã€‚
    """
    if not skill_ids: return
    
    # Step 0: æ¸…ç©ºèˆŠ Spec
    print("\n" + "="*50)
    print(f"ğŸ§¹ [Step 0] æ¸…ç©ºèˆŠè¦æ ¼æ›¸...")
    print("="*50)
    reset_skill_prompts(skill_ids)

    # Step 1: Architect
    # =========================================================================
    # [Scientific Standard Fix] é—œéµä¿®æ­£ï¼
    # ç„¡è«– current_model æ˜¯ 7B/14B/Cloudï¼Œé€™è£¡æ°¸é é–å®š 'standard_14b'ã€‚
    # é€™ä¿è­‰äº†æ‰€æœ‰æ¨¡å‹ä½¿ç”¨çš„æ˜¯åŒä¸€ä»½ã€Œæ¨™æº–é›£åº¦ã€çš„è¦æ ¼æ›¸ (Control Variable)ã€‚
    # =========================================================================
    target_tag = 'standard_14b' 
    
    print("\n" + "="*60)
    print(f"ğŸ§  [Phase 1] Architect Analysis (Model: {arch_model})")
    print(f"   ğŸ¯ Experiment Control: Using Unified Prompt Tag '{target_tag}'")
    print(f"   ğŸ¤– Coder Identity: {current_model} (Will be logged in Experiment Log)")
    print("="*60)
    
    arch_success_count = 0
    pbar_arch = tqdm(skill_ids, desc="Phase 1 (Architect)", unit="file", ncols=100)
    
    for skill_id in pbar_arch:
        pbar_arch.set_description(f"Planning: {skill_id}")
        try:
            # å‘¼å« Architectï¼Œå‚³å…¥å¼·åˆ¶çµ±ä¸€çš„ tag
            result = generate_v15_spec(skill_id, model_tag=target_tag, architect_model=arch_model)
            success = result.get('success', False)
        except Exception as e:
            tqdm.write(f"   âŒ {skill_id} Architect Error: {e}")
            success = False

        if success:
            arch_success_count += 1
    
    print(f"\nâœ… Phase 1 å®Œæˆ: {arch_success_count}/{len(skill_ids)} ä»½æ¨™æº–æ•™æ¡ˆå·²ç”Ÿæˆã€‚\n")
    
    # Step 2: Coder
    # é€™è£¡æ‰æŠŠçœŸæ­£è² è²¬å¯« code çš„æ¨¡å‹èº«åˆ†å‚³ä¸‹å»ï¼Œè¨˜éŒ„åœ¨ experiment_log
    execute_coder_phase(skill_ids, current_model, ablation_id, model_size_class, prompt_level)

def execute_coder_phase(skill_ids, current_model, ablation_id, model_size_class, prompt_level):
    print("="*50)
    print(f"ğŸ’» [Step 2] å•Ÿå‹•å·¥ç¨‹å¸«æ‰¹æ¬¡å¯¦ä½œ ({current_model})")
    print(f"   ğŸ§¬ Experiment Config: Ablation={ablation_id} | Size={model_size_class} | Prompt={prompt_level}")
    print("="*50)
    
    success_count = 0
    fail_count = 0
    
    pbar_code = tqdm(skill_ids, desc="Phase 2 (Coder)", unit="file", ncols=100)
    
    for skill_id in pbar_code:
        pbar_code.set_description(f"Coding: {skill_id}")
        
        # [Research] Pass experiment params and unpack 3 return values
        try:
            is_ok, msg, metrics = auto_generate_skill_code(
                skill_id, 
                queue=None, 
                ablation_id=ablation_id, 
                model_size_class=model_size_class,
                prompt_level=prompt_level
            )

            if is_ok:
                # [Research] Check Syntax Score
                is_valid = metrics.get('is_valid', False)
                is_failed = not is_valid
                
                if is_failed:
                    fail_count += 1
                    tqdm.write(f"   âš ï¸ {skill_id}: Validation Failed | Score=0")
                else:
                    success_count += 1
                    fixes = metrics.get('fixes', 0)
                    repair_info = f"Fixes={fixes}" if fixes > 0 else "Clean Pass"
                    tqdm.write(f"   âœ… {skill_id}: Success | Score=100 | {repair_info}")
                
                # Post-Validation Patching
                try:
                    skill_path = os.path.join(project_root, 'skills', f"{skill_id}.py")
                    if os.path.exists(skill_path):
                        with open(skill_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # --- ç¢ºä¿å¯¦é©—ç´”æ·¨åº¦ï¼šåªæœ‰ Ab3 èƒ½äº«å—æœ€å¾Œçš„ AST è£œä¸ ---
                        if ablation_id == 3:
                            patched_content = auto_patch_missing_functions(content, skill_id)
                        else:
                            patched_content = content # Ab1, Ab2 ä¿æŒã€ŒåŸå§‹æ…˜ç‹€ã€ä»¥åˆ©æ•¸æ“šå°æ¯”
                        
                        
                        if patched_content != content:
                            with open(skill_path, 'w', encoding='utf-8') as f:
                                f.write(patched_content)
                            tqdm.write(f"   ğŸ”§ {skill_id}: Patched missing functions.")
                        
                        # 2. [Versioned Storage Strategy] (Research Last Will)
                        
                        if is_failed:
                            # ğŸ’¥ [ç§‘ç ”éºæ›¸æ©Ÿåˆ¶]: å¤±æ•—ä¹Ÿè¦å­˜
                            file_name = f"{skill_id}_{model_size_class}_Ab{ablation_id}_FAILED.py"
                            tqdm.write(f"   ğŸ’¾ ä¿å­˜å£æ¨™æœ¬: {file_name}")
                        else:
                            file_name = f"{skill_id}_{model_size_class}_Ab{ablation_id}.py"

                        file_path = os.path.join(SKILLS_DIR, file_name)
                        
                        with open(file_path, "w", encoding="utf-8") as f:
                            f.write(patched_content)
                            
                        if not is_failed:
                            tqdm.write(f"   ğŸ“¦ Isolated Save: {file_name}")

                except Exception as e:
                     tqdm.write(f"   âŒ {skill_id} Patching/Saving Error: {e}")

            else:
                fail_count += 1
                tqdm.write(f"   âŒ {skill_id}: Failed ({msg})")

        except Exception as e:
            fail_count += 1
            tqdm.write(f"   âŒ {skill_id} Critical Error: {e}")

    print("\n" + "=" * 50)
    print(f"ğŸ‰ ä½œæ¥­å®Œæˆï¼")
    print(f"   æˆåŠŸ: {success_count} | å¤±æ•—: {fail_count}")
    print("=" * 50)

if __name__ == "__main__":
    app = create_app()
    
    SKILLS_DIR = os.path.join(project_root, 'skills')
    if not os.path.exists(SKILLS_DIR):
        print(f"âŒ æ‰¾ä¸åˆ°æŠ€èƒ½ç›®éŒ„: {SKILLS_DIR}")
        sys.exit(1)

    with app.app_context():
        logging.getLogger('werkzeug').setLevel(logging.ERROR)
        
        role_config = Config.MODEL_ROLES.get('coder', Config.MODEL_ROLES.get('default'))
        current_model = role_config.get('model', 'Unknown')
        
        arch_config = Config.MODEL_ROLES.get('architect', {})
        arch_model = arch_config.get('model', 'Unknown')

        print(f"ğŸš€ é–‹å§‹åŒæ­¥è³‡æ–™åº«èˆ‡å¯¦é«”æª”æ¡ˆ (V9.2.0 Scientific Standard Edition)")
        print(f"ğŸ§  æ¶æ§‹å¸«æ¨¡å‹ (Architect): \033[1;35m{arch_model}\033[0m")        
        print(f"ğŸ¤– å·¥ç¨‹å¸«æ¨¡å‹ (Coder): \033[1;36m{current_model}\033[0m")         
        # --- 1. äº’å‹•ç¯©é¸ ---
        curriculums = [r[0] for r in db.session.query(distinct(SkillCurriculum.curriculum)).order_by(SkillCurriculum.curriculum).all()]
        selected_curr = get_user_selection(curriculums, "è«‹é¸æ“‡èª²ç¶±:")

        q_grade = db.session.query(distinct(SkillCurriculum.grade))
        if selected_curr: q_grade = q_grade.filter(SkillCurriculum.curriculum == selected_curr)
        grades = [r[0] for r in q_grade.order_by(SkillCurriculum.grade).all()]
        selected_grade = get_user_selection(grades, "è«‹é¸æ“‡å¹´ç´š:")

        q_vol = db.session.query(distinct(SkillCurriculum.volume))
        if selected_curr: q_vol = q_vol.filter(SkillCurriculum.curriculum == selected_curr)
        if selected_grade: q_vol = q_vol.filter(SkillCurriculum.grade == selected_grade)
        volumes = [r[0] for r in q_vol.all()]
        selected_vol = get_user_selection(volumes, "è«‹é¸æ“‡å†Šåˆ¥:")

        q_chap = db.session.query(distinct(SkillCurriculum.chapter))
        if selected_curr: q_chap = q_chap.filter(SkillCurriculum.curriculum == selected_curr)
        if selected_grade: q_chap = q_chap.filter(SkillCurriculum.grade == selected_grade)
        if selected_vol: q_chap = q_chap.filter(SkillCurriculum.volume == selected_vol)
        chapters = [r[0] for r in q_chap.all()]
        selected_chap = get_user_selection(chapters, "è«‹é¸æ“‡ç« ç¯€:")

        selected_skill_id = None
        if any([selected_curr, selected_grade, selected_vol, selected_chap]):
            q_skill = db.session.query(SkillInfo.skill_id, SkillInfo.skill_ch_name).join(SkillCurriculum).filter(SkillInfo.is_active == True)
            if selected_curr: q_skill = q_skill.filter(SkillCurriculum.curriculum == selected_curr)
            if selected_grade: q_skill = q_skill.filter(SkillCurriculum.grade == selected_grade)
            if selected_vol: q_skill = q_skill.filter(SkillCurriculum.volume == selected_vol)
            if selected_chap: q_skill = q_skill.filter(SkillCurriculum.chapter == selected_chap)
            
            skills_raw = q_skill.order_by(SkillCurriculum.display_order).all()
            skill_options = [f"{s.skill_id} | {s.skill_ch_name}" for s in skills_raw]
            
            if skill_options:
                selected_skill_str = get_user_selection(skill_options, "è«‹é¸æ“‡å–®ä¸€æŠ€èƒ½ (Optional):")
                if selected_skill_str:
                    selected_skill_id = selected_skill_str.split(' | ')[0].strip()

        is_full_scan = all(x is None for x in [selected_curr, selected_grade, selected_vol, selected_chap, selected_skill_id])

        # --- 2. æŸ¥è©¢ç›®æ¨™æŠ€èƒ½ ---
        print("\nğŸ” æ­£åœ¨æŸ¥è©¢ç›®æ¨™æŠ€èƒ½...")
        query = db.session.query(SkillInfo.skill_id).join(SkillCurriculum).filter(SkillInfo.is_active == True)
        
        if selected_curr: query = query.filter(SkillCurriculum.curriculum == selected_curr)
        if selected_grade: query = query.filter(SkillCurriculum.grade == selected_grade)
        if selected_vol: query = query.filter(SkillCurriculum.volume == selected_vol)
        if selected_chap: query = query.filter(SkillCurriculum.chapter == selected_chap)
        if selected_skill_id: query = query.filter(SkillInfo.skill_id == selected_skill_id)
        
        target_skill_ids = set(r[0] for r in query.all())

        # --- 3. æƒæå¯¦é«”æª”æ¡ˆ by glob ---
        files = glob.glob(os.path.join(SKILLS_DIR, "*.py"))
        file_skill_ids = set()
        for f in files:
            fname = os.path.basename(f)
            if fname not in PROTECTED_FILES:
                file_skill_ids.add(fname.replace('.py', ''))
        
        to_create = target_skill_ids - file_skill_ids
        existing_in_scope = target_skill_ids.intersection(file_skill_ids)
        to_delete = set()
        if is_full_scan:
            all_active_ids = set(r[0] for r in db.session.query(SkillInfo.skill_id).filter_by(is_active=True).all())
            to_delete = file_skill_ids - all_active_ids

        print(f"\nğŸ“Š [ç¯„åœåˆ†æçµæœ]")
        print(f"   - ç¯„åœå…§æŠ€èƒ½ç¸½æ•¸: {len(target_skill_ids)}")
        print(f"   - ç¼ºå¤±æª”æ¡ˆ (éœ€æ–°å¢): {len(to_create)}")
        print(f"   - ç¾æœ‰æª”æ¡ˆ (å¯æ›´æ–°): {len(existing_in_scope)}")
        if is_full_scan:
            print(f"   - å­¤å…’æª”æ¡ˆ (éœ€åˆªé™¤): {len(to_delete)}")

        if not target_skill_ids and not to_delete:
            print("âœ… ç¯„åœå…§ç„¡æŠ€èƒ½æˆ–ç„¡éœ€æ“ä½œï¼ŒçµæŸã€‚")
            sys.exit(0)

        # [Research Edition] æ•´åˆæ¨¡å¼ 3 èˆ‡åƒæ•¸æå‡
        print("\nè«‹é¸æ“‡æ“ä½œæ¨¡å¼:")
        print("   [1] åƒ…ç”Ÿæˆç¼ºå¤±æª”æ¡ˆ (Safe Mode)")
        print("   [2] å¼·åˆ¶é‡æ–°ç”Ÿæˆç¯„åœå…§æ‰€æœ‰æª”æ¡ˆ (Overwrite All)")
        print("   [3] åƒ…ç”Ÿæˆé¸å®šç¯„åœå…§å°šæœªç”Ÿæˆçš„æª”æ¡ˆ (Incremental Scope)") 
        print("   [4] å°ˆå®¶åˆ†å·¥æ¨¡å¼ï¼šå…¨éƒ¨é‡è·‘ (Full Pipeline + AST Healing)") 
        if to_delete:
            print("   [5] æ¸…ç†å­¤å…’æª”æ¡ˆ (Delete Orphans)")
        
        mode = input("ğŸ‘‰ è«‹è¼¸å…¥é¸é …: ").strip()
        
        list_to_process = []
        run_full_pipeline = False
        
        # åˆ¤æ–·è™•ç†æ¸…å–®
        if mode == '1':
            list_to_process = sorted(list(to_create))
        elif mode == '2':
            list_to_process = sorted(list(target_skill_ids)) # å¼·åˆ¶ç¯„åœå…§å…¨è·‘
        elif mode == '3':
            list_to_process = sorted(list(target_skill_ids.intersection(to_create))) # ç¯„åœå…§ä¸”ç¼ºå¤±
        elif mode == '4':
            list_to_process = sorted(list(target_skill_ids))
            run_full_pipeline = True
        elif mode == '5' and to_delete:
            print("\nğŸ—‘ï¸  æ­£åœ¨æ¸…ç†å­¤å…’æª”æ¡ˆ...")
            for skill_id in tqdm(to_delete, desc="Deleting"):
                try:
                    os.remove(os.path.join(SKILLS_DIR, f"{skill_id}.py"))
                except Exception as e:
                    print(f"   âŒ åˆªé™¤å¤±æ•—: {e}")
            print("âœ… æ¸…ç†å®Œæˆã€‚")
            sys.exit(0)
        else:
            print("âŒ ç„¡æ•ˆé¸é …æˆ–ç„¡æ“ä½œã€‚")
            sys.exit(0)

        # --- [Research] å¯¦é©—åƒæ•¸è¨­å®š ---
        if mode in ['1', '2', '3', '4']:
            print("\n" + "="*60)
            print("ğŸ§ª [å¯¦é©—è®Šå› æ§åˆ¶] è«‹é¸æ“‡æœ¬æ¬¡ç”Ÿæˆçš„ Ablation å±¤ç´š:")
            print("   1: Bare (Baseline)    -> ç°¡å–® Prompt + ç„¡ä¿®å¾© (æ¸¬è©¦åŸç”Ÿèƒ½åŠ›)")
            print("   2: Engineered (Prompt) -> V15.1 Spec + ç„¡ä¿®å¾© (æ¸¬è©¦æç¤ºå·¥ç¨‹è²¢ç»)")
            print("   3: Full Healing (Sys)  -> V15.1 Spec + Regex/AST ä¿®å¾© (æ¸¬è©¦ç³»çµ±å…¨èƒ½åŠ›)")
            print("="*60)
            
            ab_input = input("   ğŸ‘‰ è¼¸å…¥ Ablation ID (1/2/3, é è¨­ 3): ").strip()
            ablation_id = int(ab_input) if ab_input in ['1', '2', '3'] else 3
            
            # å°æ‡‰å¯¦é©—æè¿°ï¼Œæ–¹ä¾¿æ—¥èªŒç´€éŒ„
            ab_desc = {1: "Bare", 2: "Engineered-Only", 3: "Full-Healing"}
            print(f"âœ… å·²è¨­å®šå¯¦é©—çµ„åˆ¥ï¼š{ab_desc[ablation_id]}")

            # --- [UI Improvement] Model Size Class Selection ---
            print("\n" + "="*60)
            print("ğŸ“ [å¯¦é©—è®Šå› æ§åˆ¶] è«‹é¸æ“‡ Model Size Class:")
            print("   1: Cloud     -> å¤§å‹æ¨¡å‹ (å¦‚ Gemini, GPT-4)")
            print("   2: Local 14B -> ä¸­å‹æ¨¡å‹ (å¦‚ Qwen 2.5-14B)")
            print("   3: Edge 7B   -> å°å‹æ¨¡å‹ (å¦‚ Llama 3-8B, Phi-3)")
            print("="*60)
            
            size_map = {'1': 'Cloud', '2': '14B', '3': '7B'}
            ms_input = input("   ğŸ‘‰ è¼¸å…¥é¸é … (1/2/3, é è¨­ 1): ").strip()
            # é è¨­ç‚º 'Cloud'
            model_size_class = size_map.get(ms_input, 'Cloud')
            print(f"âœ… å·²è¨­å®šæ¨¡å‹é‡ç´šï¼š{model_size_class}")
            
            prompt_level = ab_desc[ablation_id] # Update prompt_level to match description

        if not list_to_process:
            print("âœ… æ²’æœ‰éœ€è¦è™•ç†çš„æª”æ¡ˆã€‚")
            sys.exit(0)

        # Confirm
        count = len(list_to_process)
        print(f"\nâš ï¸  [æ³¨æ„] æº–å‚™é–‹å§‹")
        print(f"   æ•¸é‡: {count} é¡Œ")
        confirm = input("   ç¢ºå®šè¦ç¹¼çºŒå—? (y/n): ").strip().lower()
        if confirm != 'y':
            sys.exit(0)

        # Execution
        if run_full_pipeline:
            run_expert_pipeline(
                list_to_process, 
                arch_model, 
                current_model,
                ablation_id,
                model_size_class,
                prompt_level
            )
        else:
            # Code Gen Only (Phase 2)
            execute_coder_phase(
                list_to_process, 
                current_model, 
                ablation_id, 
                model_size_class, 
                prompt_level
            )