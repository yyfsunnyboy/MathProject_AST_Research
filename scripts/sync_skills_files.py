# -*- coding: utf-8 -*-
# ==============================================================================
# ID: sync_skills_files.py
# Version: v9.0.0 (Research Edition - AST Self-Healing & 3x3 Experiment)
# Description:
#   è² è²¬åŒæ­¥è³‡æ–™åº«ä¸­çš„æŠ€èƒ½æ¸…å–®èˆ‡æœ¬åœ°å¯¦é«”æª”æ¡ˆã€‚
#   [Experiment]: æ”¯æ´ 3x3 å¯¦é©— (3 Model Sizes x 3 Prompt Levels/Ablation IDs)
#   [Self-Healing]: æ•´åˆ AST ä¿®å¾©å¼•æ“èˆ‡ auto_patch_missing_functions
# ==============================================================================

import sys
import os
import glob
import time
import logging
import ast # [Research] Import AST for robust parsing
from datetime import datetime
from tqdm import tqdm
from sqlalchemy import distinct

# ==============================================================================
# 1. æ™ºæ…§è·¯å¾‘è¨­å®š (è‡ªå‹•åµæ¸¬å°ˆæ¡ˆæ ¹ç›®éŒ„)
# ==============================================================================
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = current_dir
while not os.path.exists(os.path.join(project_root, 'app.py')):
    parent = os.path.dirname(project_root)
    if parent == project_root:
        print("âŒ éŒ¯èª¤ï¼šç„¡æ³•å®šä½å°ˆæ¡ˆæ ¹ç›®éŒ„ (æ‰¾ä¸åˆ° app.py)")
        sys.exit(1)
    project_root = parent

if project_root not in sys.path:
    sys.path.insert(0, project_root)

from app import create_app
from models import db, SkillInfo, SkillCurriculum, TextbookExample
# [Research] Import requested functions
from core.code_generator import auto_generate_skill_code, inject_robust_dispatcher
from core.prompt_architect import generate_v15_spec
from config import Config

PROTECTED_FILES = {
    "Example_Program.py",
    "__init__.py", 
    "base_skill.py"
}

def get_user_selection(options, prompt_text):
    if not options: return None
    # [Fix] ç§»é™¤ sorted()ï¼Œä¿ç•™å¤–éƒ¨å‚³å…¥çš„æ­£ç¢ºé †åº (display_order)
    options = [o for o in options if o is not None]
    
    print(f"\n{prompt_text}")
    print("   [0] ALL (å…¨éƒ¨/è·³é)")
    for i, opt in enumerate(options, 1):
        print(f"   [{i}] {opt}")
        
    while True:
        try:
            choice = input("ğŸ‘‰ è«‹é¸æ“‡ (è¼¸å…¥æ•¸å­—): ").strip()
            if choice == '0': return None
            idx = int(choice) - 1
            if 0 <= idx < len(options): return options[idx]
            print("âŒ è¼¸å…¥ç„¡æ•ˆï¼Œè«‹é‡è©¦ã€‚")
        except ValueError:
            print("âŒ è«‹è¼¸å…¥æ•¸å­—ã€‚")

def reset_skill_prompts(skill_ids):
    """
    [Fix] ä½¿ç”¨ç©ºå­—ä¸² "" è€Œé None ä¾†æ¸…ç©º Promptã€‚
    è§£æ±º sqlite3.IntegrityError: NOT NULL constraint failed
    """
    if not skill_ids: return
    try:
        SkillInfo.query.filter(SkillInfo.skill_id.in_(skill_ids)).update({SkillInfo.gemini_prompt: ""}, synchronize_session=False)
        db.session.commit()
        tqdm.write(f"ğŸ§¹ å·²æ¸…ç©º {len(skill_ids)} ç­†èˆŠè¦æ ¼æ›¸ï¼Œæº–å‚™é‡æ–°ç”Ÿæˆã€‚")
    except Exception as e:
        tqdm.write(f"âš ï¸ æ¸…ç©ºèˆŠè¦æ ¼å¤±æ•—: {e}")
        db.session.rollback()

def auto_patch_missing_functions(code_content, skill_id):
    """
    [Research Edition] ä½¿ç”¨ AST é€²è¡Œçµæ§‹åŒ–åµæ¸¬èˆ‡ä¿®å¾©
    """
    patches = []
    tree = None
    
    try:
        tree = ast.parse(code_content)
    except Exception as e:
        tqdm.write(f"âš ï¸ AST Parse Error for {skill_id}: {e}")
        pass # Continue to try raw string check if AST fails initially

    has_generate = False
    has_check = False
    generate_args = []
    
    if tree:
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if node.name == 'generate':
                    has_generate = True
                    generate_args = [a.arg for a in node.args.args]
                elif node.name == 'check':
                    has_check = True

    # 1. æª¢æŸ¥ generate é€²å…¥é»
    if not has_generate:
        # Fallback raw check
        if "def generate" not in code_content:
            # å°‹æ‰¾æ˜¯å¦æœ‰é¡ä¼¼ generate_number_line é€™æ¨£çš„è®Šé«”
            import re
            alt_gen = re.findall(r'def (generate_[a-zA-Z0-9_]+)\(', code_content)
            if alt_gen:
                patches.append(f"\n# [Auto-Fix] Alias {alt_gen[0]} to generate")
                patches.append(f"generate = {alt_gen[0]}")
            else:
                # æ³¨å…¥å¼·åŠ›èª¿åº¦å™¨
                patches.append("\n# [Auto-Fix] Injected Robust Dispatcher")
                # é€™è£¡ç›´æ¥èª¿ç”¨ core logic (é›–ç„¶ inject_robust_dispatcher æ˜¯è™•ç† string, é€™è£¡æˆ‘å€‘æ‰‹å‹•è£œ function)
                patches.append("def generate(level=1, **kwargs): return {'question_text': 'é¡Œç›®ç”Ÿæˆå¤±æ•—(Dispatcher Missing)', 'correct_answer': 'N/A'}")
    
    elif not any(arg in ['level', 'kwargs'] for arg in generate_args):
        # å¦‚æœæœ‰ generate ä½†æ²’æœ‰åƒæ•¸ï¼Œé€™æœƒå°è‡´ crash
        # ä½¿ç”¨ AST transformer å¤ªè¤‡é›œï¼Œé€™è£¡æ”¹ç”¨ç°¡å–®æ›¿æ›ï¼Œä½†åƒ…é‡å°å®šç¾©è¡Œ
        code_content = code_content.replace("def generate():", "def generate(level=1, **kwargs):")

    # 2. æª¢æŸ¥ check å‡½å¼
    if not has_check and "def check" not in code_content:
        patches.append("\n# [Auto-Fix] Emergency Fallback Check")
        patches.append("def check(u, c): return {'correct': False, 'result': 'è©•åˆ†ç³»çµ±ç•°å¸¸(Check Missing)'}")

    if patches:
        tqdm.write(f"ğŸ”§ {skill_id}: Detected missing functions via AST. Applying patches.")
        # [Optimize] ç¢ºä¿æˆ‘å€‘ä¸æœƒé‡è¤‡æ³¨å…¥
        return code_content + "\n" + "\n".join(patches)
    
    return code_content

def run_expert_pipeline(skill_ids, arch_model, current_model, ablation_id, model_size_class, prompt_level):
    """
    åŸ·è¡Œå®Œæ•´çš„å°ˆå®¶åˆ†å·¥æµç¨‹ (Phase 1 + Phase 2)
    [Research]: Supports Ablation Logic
    """
    if not skill_ids: return
    
    # Step 0: æ¸…ç©ºèˆŠ Spec
    print("\n" + "="*50)
    print(f"ğŸ§¹ [Step 0] æ¸…ç©ºèˆŠè¦æ ¼æ›¸...")
    print("="*50)
    reset_skill_prompts(skill_ids)

    # Step 1: Architect
    # --- Smart Tag Detection ---
    c_model = current_model.lower()
    target_tag = 'local_14b' 
    
    if any(x in c_model for x in ['gemini', 'gpt', 'claude']): 
        target_tag = 'cloud_pro' 
    elif '70b' in c_model or '32b' in c_model or '14b' in c_model: 
        target_tag = 'local_14b'
    elif 'phi' in c_model or '7b' in c_model or '8b' in c_model: 
        target_tag = 'edge_7b'
    
    print("\n" + "="*60)
    print(f"ğŸ§  [Phase 1] V9 Architect Analysis (Model: {arch_model})")
    print(f"   Target Strategy: '{target_tag}'")
    print("="*60)
    
    arch_success_count = 0
    pbar_arch = tqdm(skill_ids, desc="Phase 1 (Architect)", unit="file", ncols=100)
    
    for skill_id in pbar_arch:
        pbar_arch.set_description(f"Planning: {skill_id}")
        try:
             # [Research] Prompt Level could potentially influence Architect too, but mostly Coder
             # For now, we keep Architect standard
            result = generate_v15_spec(skill_id, model_tag=target_tag, architect_model=arch_model)
            success = result.get('success', False)
        except Exception as e:
            tqdm.write(f"   âŒ {skill_id} Architect Error: {e}")
            success = False

        if success:
            arch_success_count += 1
    
    print(f"\nâœ… Phase 1 å®Œæˆ: {arch_success_count}/{len(skill_ids)} ä»½æ•™æ¡ˆå·²ç”Ÿæˆã€‚\n")
    
    # Step 2: Coder
    execute_coder_phase(skill_ids, current_model, ablation_id, model_size_class, prompt_level)

def execute_coder_phase(skill_ids, current_model, ablation_id, model_size_class, prompt_level):
    print("="*50)
    print(f"ğŸ’» [Step 2] å•Ÿå‹•å·¥ç¨‹å¸«æ‰¹æ¬¡å¯¦ä½œ ({current_model})")
    print(f"   ğŸ§¬ Experiment Config: Ablation={ablation_id} | Size={model_size_class} | Prompt={prompt_level}")
    print("="*50)
    
    success_count = 0
    fail_count = 0
    
    pbar_code = tqdm(skill_ids, desc="Phase 2 (Coder)", unit="file", ncols=100)
    
    for skill_id in pbar_code:
        pbar_code.set_description(f"Coding: {skill_id}")
        
        # [Research] Pass experiment params and unpack 3 return values
        try:
            is_ok, msg, metrics = auto_generate_skill_code(
                skill_id, 
                queue=None, 
                ablation_id=ablation_id, 
                model_size_class=model_size_class,
                prompt_level=prompt_level
            )

            if is_ok:
                # [Research] Check Syntax Score
                score_val = metrics.get('score_syntax', 0)
                is_failed = score_val < 100
                
                if is_failed:
                    fail_count += 1
                    error_msg = "Syntax Error"
                    tqdm.write(f"   âš ï¸ {skill_id}: Validation Failed | Score={score_val}")
                else:
                    success_count += 1
                    repair_info = f"Fixes={metrics.get('fixes',0)}" if metrics.get('fixes',0) > 0 else "Clean Pass"
                    score = f"Score={score_val}"
                    tqdm.write(f"   âœ… {skill_id}: Success | {score} | {repair_info}")
                
                # Post-Validation Patching
                try:
                    skill_path = os.path.join(project_root, 'skills', f"{skill_id}.py")
                    if os.path.exists(skill_path):
                        with open(skill_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # --- ç¢ºä¿å¯¦é©—ç´”æ·¨åº¦ï¼šåªæœ‰ Ab3 èƒ½äº«å—æœ€å¾Œçš„ AST è£œä¸ ---
                        if ablation_id == 3:
                            patched_content = auto_patch_missing_functions(content, skill_id)
                        else:
                            patched_content = content # Ab1, Ab2 ä¿æŒã€ŒåŸå§‹æ…˜ç‹€ã€ä»¥åˆ©æ•¸æ“šå°æ¯”
                        
                        # 1. Update the main file (Latest Run) - Only if success? User didn't specify, but implies fails should be isolated.
                        # But code_generator already wrote the file to skill_path.
                        # We will patch it regardless.
                        
                        if patched_content != content:
                            with open(skill_path, 'w', encoding='utf-8') as f:
                                f.write(patched_content)
                            tqdm.write(f"   ğŸ”§ {skill_id}: Patched missing functions.")
                        
                        # 2. [Versioned Storage Strategy] (Research Last Will)
                        current_ablation_id = ablation_id
                        
                        if is_failed:
                            # ğŸ’¥ [ç§‘ç ”éºæ›¸æ©Ÿåˆ¶]: å¤±æ•—ä¹Ÿè¦å­˜
                            file_name = f"{skill_id}_Ab{ablation_id}_FAILED.py"
                            tqdm.write(f"   ğŸ’¾ ä¿å­˜å£æ¨™æœ¬: {file_name}")
                        else:
                            file_name = f"{skill_id}_Ab{ablation_id}.py"

                        file_path = os.path.join(SKILLS_DIR, file_name)
                        
                        with open(file_path, "w", encoding="utf-8") as f:
                            f.write(patched_content)
                            
                        if not is_failed:
                            tqdm.write(f"   ğŸ“¦ Isolated Save: {file_name}")

                except Exception as e:
                     tqdm.write(f"   âŒ {skill_id} Patching/Saving Error: {e}")

            else:
                fail_count += 1
                tqdm.write(f"   âŒ {skill_id}: Failed ({msg})")

        except Exception as e:
            fail_count += 1
            tqdm.write(f"   âŒ {skill_id} Critical Error: {e}")

    print("\n" + "=" * 50)
    print(f"ğŸ‰ ä½œæ¥­å®Œæˆï¼")
    print(f"   æˆåŠŸ: {success_count} | å¤±æ•—: {fail_count}")
    print("=" * 50)

if __name__ == "__main__":
    app = create_app()
    
    SKILLS_DIR = os.path.join(project_root, 'skills')
    if not os.path.exists(SKILLS_DIR):
        print(f"âŒ æ‰¾ä¸åˆ°æŠ€èƒ½ç›®éŒ„: {SKILLS_DIR}")
        sys.exit(1)

    with app.app_context():
        logging.getLogger('werkzeug').setLevel(logging.ERROR)
        
        role_config = Config.MODEL_ROLES.get('coder', Config.MODEL_ROLES.get('default'))
        current_model = role_config.get('model', 'Unknown')
        
        arch_config = Config.MODEL_ROLES.get('architect', {})
        arch_model = arch_config.get('model', 'Unknown')

        print(f"ğŸš€ é–‹å§‹åŒæ­¥è³‡æ–™åº«èˆ‡å¯¦é«”æª”æ¡ˆ (Research Edition)")
        print(f"ğŸ§  æ¶æ§‹å¸«æ¨¡å‹ (Architect): \033[1;35m{arch_model}\033[0m")        
        print(f"ğŸ¤– å·¥ç¨‹å¸«æ¨¡å‹ (Coder): \033[1;36m{current_model}\033[0m")         
        # --- 1. äº’å‹•ç¯©é¸ (ä¿ç•™åŸé‚è¼¯) ---
        curriculums = [r[0] for r in db.session.query(distinct(SkillCurriculum.curriculum)).order_by(SkillCurriculum.curriculum).all()]
        selected_curr = get_user_selection(curriculums, "è«‹é¸æ“‡èª²ç¶±:")

        q_grade = db.session.query(distinct(SkillCurriculum.grade))
        if selected_curr: q_grade = q_grade.filter(SkillCurriculum.curriculum == selected_curr)
        grades = [r[0] for r in q_grade.order_by(SkillCurriculum.grade).all()]
        selected_grade = get_user_selection(grades, "è«‹é¸æ“‡å¹´ç´š:")

        q_vol = db.session.query(distinct(SkillCurriculum.volume))
        if selected_curr: q_vol = q_vol.filter(SkillCurriculum.curriculum == selected_curr)
        if selected_grade: q_vol = q_vol.filter(SkillCurriculum.grade == selected_grade)
        volumes = [r[0] for r in q_vol.all()]
        selected_vol = get_user_selection(volumes, "è«‹é¸æ“‡å†Šåˆ¥:")

        q_chap = db.session.query(distinct(SkillCurriculum.chapter))
        if selected_curr: q_chap = q_chap.filter(SkillCurriculum.curriculum == selected_curr)
        if selected_grade: q_chap = q_chap.filter(SkillCurriculum.grade == selected_grade)
        if selected_vol: q_chap = q_chap.filter(SkillCurriculum.volume == selected_vol)
        chapters = [r[0] for r in q_chap.all()]
        selected_chap = get_user_selection(chapters, "è«‹é¸æ“‡ç« ç¯€:")

        selected_skill_id = None
        if any([selected_curr, selected_grade, selected_vol, selected_chap]):
            q_skill = db.session.query(SkillInfo.skill_id, SkillInfo.skill_ch_name).join(SkillCurriculum).filter(SkillInfo.is_active == True)
            if selected_curr: q_skill = q_skill.filter(SkillCurriculum.curriculum == selected_curr)
            if selected_grade: q_skill = q_skill.filter(SkillCurriculum.grade == selected_grade)
            if selected_vol: q_skill = q_skill.filter(SkillCurriculum.volume == selected_vol)
            if selected_chap: q_skill = q_skill.filter(SkillCurriculum.chapter == selected_chap)
            
            skills_raw = q_skill.order_by(SkillCurriculum.display_order).all()
            skill_options = [f"{s.skill_id} | {s.skill_ch_name}" for s in skills_raw]
            
            if skill_options:
                selected_skill_str = get_user_selection(skill_options, "è«‹é¸æ“‡å–®ä¸€æŠ€èƒ½ (Optional):")
                if selected_skill_str:
                    selected_skill_id = selected_skill_str.split(' | ')[0].strip()

        is_full_scan = all(x is None for x in [selected_curr, selected_grade, selected_vol, selected_chap, selected_skill_id])

        # --- 2. æŸ¥è©¢ç›®æ¨™æŠ€èƒ½ ---
        print("\nğŸ” æ­£åœ¨æŸ¥è©¢ç›®æ¨™æŠ€èƒ½...")
        query = db.session.query(SkillInfo.skill_id).join(SkillCurriculum).filter(SkillInfo.is_active == True)
        
        if selected_curr: query = query.filter(SkillCurriculum.curriculum == selected_curr)
        if selected_grade: query = query.filter(SkillCurriculum.grade == selected_grade)
        if selected_vol: query = query.filter(SkillCurriculum.volume == selected_vol)
        if selected_chap: query = query.filter(SkillCurriculum.chapter == selected_chap)
        if selected_skill_id: query = query.filter(SkillInfo.skill_id == selected_skill_id)
        
        target_skill_ids = set(r[0] for r in query.all())

        # --- 3. æƒæå¯¦é«”æª”æ¡ˆ by glob ---
        files = glob.glob(os.path.join(SKILLS_DIR, "*.py"))
        file_skill_ids = set()
        for f in files:
            fname = os.path.basename(f)
            if fname not in PROTECTED_FILES:
                file_skill_ids.add(fname.replace('.py', ''))
        
        to_create = target_skill_ids - file_skill_ids
        existing_in_scope = target_skill_ids.intersection(file_skill_ids)
        to_delete = set()
        if is_full_scan:
            all_active_ids = set(r[0] for r in db.session.query(SkillInfo.skill_id).filter_by(is_active=True).all())
            to_delete = file_skill_ids - all_active_ids

        print(f"\nğŸ“Š [ç¯„åœåˆ†æçµæœ]")
        print(f"   - ç¯„åœå…§æŠ€èƒ½ç¸½æ•¸: {len(target_skill_ids)}")
        print(f"   - ç¼ºå¤±æª”æ¡ˆ (éœ€æ–°å¢): {len(to_create)}")
        print(f"   - ç¾æœ‰æª”æ¡ˆ (å¯æ›´æ–°): {len(existing_in_scope)}")
        if is_full_scan:
            print(f"   - å­¤å…’æª”æ¡ˆ (éœ€åˆªé™¤): {len(to_delete)}")

        if not target_skill_ids and not to_delete:
            print("âœ… ç¯„åœå…§ç„¡æŠ€èƒ½æˆ–ç„¡éœ€æ“ä½œï¼ŒçµæŸã€‚")
            sys.exit(0)

        # [Research Edition] æ•´åˆæ¨¡å¼ 3 èˆ‡åƒæ•¸æå‡
        print("\nè«‹é¸æ“‡æ“ä½œæ¨¡å¼:")
        print("   [1] åƒ…ç”Ÿæˆç¼ºå¤±æª”æ¡ˆ (Safe Mode)")
        print("   [2] å¼·åˆ¶é‡æ–°ç”Ÿæˆç¯„åœå…§æ‰€æœ‰æª”æ¡ˆ (Overwrite All)")
        print("   [3] åƒ…ç”Ÿæˆé¸å®šç¯„åœå…§å°šæœªç”Ÿæˆçš„æª”æ¡ˆ (Incremental Scope)") 
        print("   [4] å°ˆå®¶åˆ†å·¥æ¨¡å¼ï¼šå…¨éƒ¨é‡è·‘ (Full Pipeline + AST Healing)") 
        if to_delete:
            print("   [5] æ¸…ç†å­¤å…’æª”æ¡ˆ (Delete Orphans)")
        
        mode = input("ğŸ‘‰ è«‹è¼¸å…¥é¸é …: ").strip()
        
        list_to_process = []
        run_full_pipeline = False
        
        # åˆ¤æ–·è™•ç†æ¸…å–®
        if mode == '1':
            list_to_process = sorted(list(to_create))
        elif mode == '2':
            list_to_process = sorted(list(target_skill_ids)) # å¼·åˆ¶ç¯„åœå…§å…¨è·‘
        elif mode == '3':
            list_to_process = sorted(list(target_skill_ids.intersection(to_create))) # ç¯„åœå…§ä¸”ç¼ºå¤±
        elif mode == '4':
            list_to_process = sorted(list(target_skill_ids))
            run_full_pipeline = True
        elif mode == '5' and to_delete:
            print("\nğŸ—‘ï¸  æ­£åœ¨æ¸…ç†å­¤å…’æª”æ¡ˆ...")
            for skill_id in tqdm(to_delete, desc="Deleting"):
                try:
                    os.remove(os.path.join(SKILLS_DIR, f"{skill_id}.py"))
                except Exception as e:
                    print(f"   âŒ åˆªé™¤å¤±æ•—: {e}")
            print("âœ… æ¸…ç†å®Œæˆã€‚")
            sys.exit(0)
        else:
            print("âŒ ç„¡æ•ˆé¸é …æˆ–ç„¡æ“ä½œã€‚")
            sys.exit(0)

# --- [Research] å¯¦é©—åƒæ•¸è¨­å®šæå‡ (V15.2 Research Edition) ---
        if mode in ['1', '2', '3', '4']:
            print("\n" + "="*60)
            print("ğŸ§ª [å¯¦é©—è®Šå› æ§åˆ¶] è«‹é¸æ“‡æœ¬æ¬¡ç”Ÿæˆçš„ Ablation å±¤ç´š:")
            print("   1: Bare (Baseline)    -> ç°¡å–® Prompt + ç„¡ä¿®å¾© (æ¸¬è©¦åŸç”Ÿèƒ½åŠ›)")
            print("   2: Engineered (Prompt) -> V15.1 Spec + ç„¡ä¿®å¾© (æ¸¬è©¦æç¤ºå·¥ç¨‹è²¢ç»)")
            print("   3: Full Healing (Sys)  -> V15.1 Spec + Regex/AST ä¿®å¾© (æ¸¬è©¦ç³»çµ±å…¨èƒ½åŠ›)")
            print("="*60)
            
            ab_input = input("   ğŸ‘‰ è¼¸å…¥ Ablation ID (1/2/3, é è¨­ 3): ").strip()
            ablation_id = int(ab_input) if ab_input in ['1', '2', '3'] else 3
            
            # å°æ‡‰å¯¦é©—æè¿°ï¼Œæ–¹ä¾¿æ—¥èªŒç´€éŒ„
            ab_desc = {1: "Bare", 2: "Engineered-Only", 3: "Full-Healing"}
            print(f"âœ… å·²è¨­å®šå¯¦é©—çµ„åˆ¥ï¼š{ab_desc[ablation_id]}")

            ms_input = input("\n   ğŸ‘‰ è¼¸å…¥ Model Size Class (é è¨­ 14B): ").strip()
            model_size_class = ms_input if ms_input else "14B"
            prompt_level = ab_desc[ablation_id] # Update prompt_level to match description

        if not list_to_process:
            print("âœ… æ²’æœ‰éœ€è¦è™•ç†çš„æª”æ¡ˆã€‚")
            sys.exit(0)

        # Confirm
        count = len(list_to_process)
        print(f"\nâš ï¸  [æ³¨æ„] æº–å‚™é–‹å§‹")
        print(f"   æ•¸é‡: {count} é¡Œ")
        confirm = input("   ç¢ºå®šè¦ç¹¼çºŒå—? (y/n): ").strip().lower()
        if confirm != 'y':
            sys.exit(0)

        # Execution
        if run_full_pipeline:
            run_expert_pipeline(
                list_to_process, 
                arch_model, 
                current_model,
                ablation_id,
                model_size_class,
                prompt_level
            )
        else:
            # Code Gen Only (Phase 2)
            execute_coder_phase(
                list_to_process, 
                current_model, 
                ablation_id, 
                model_size_class, 
                prompt_level
            )