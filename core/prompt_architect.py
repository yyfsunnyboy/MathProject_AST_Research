# -*- coding: utf-8 -*-
# [core/prompt_architect.py] V15.2 Research Edition

import os
import json
import re
import time
from datetime import datetime
from flask import current_app
from models import db, SkillInfo, SkillGenCodePrompt, TextbookExample
from core.ai_wrapper import get_ai_client

# ==============================================================================
# V15.2 HYBRID SYSTEM PROMPT (å»£ç¾©å»ºæ¨¡æ¶æ§‹å¸«)
# ==============================================================================
V15_1_SYSTEM_PROMPT = """ã€ä»»å‹™ã€‘ï¼šK12 æ•¸å­¸ç§‘ç ”æ¶æ§‹å¸« (Dynamic Logic Architect)

### â›” æ ¸å¿ƒè¦å‰‡ï¼š
1. ç›®æ¨™ï¼šå°‡ RAG æ¯é¡Œè½‰åŒ–ç‚ºã€Œå»£ç¾©æ•¸å­¸å»ºæ¨¡ã€é‚è¼¯ã€‚
2. å»¢é™¤æ¨£æ¿åŒ–æ€è€ƒï¼šåš´ç¦ç›´æ¥è¤‡è£½æ¯é¡Œæ•¸å€¼ã€‚
3. è¼¸å‡ºæ ¼å¼ï¼šåƒ…è¼¸å‡º Python ç¨‹å¼ç¢¼é‚è¼¯ï¼ˆå®šç¾© q èˆ‡ aï¼‰ï¼Œåš´ç¦è¼¸å‡º Markdown æ¨™ç±¤ã€‚
4. é‡å°ã€Œç´”è¨ˆç®—é¡Œã€ï¼šå°ˆæ³¨æ–¼é‹ç®—çµæ§‹çš„éš¨æ©ŸåŒ–ï¼Œåš´ç¦è‡ªå‰µç„¡é—œæƒ…å¢ƒã€‚
5. **[å…¨é‡åƒæ•¸åŒ–å¼·åˆ¶]ï¼šè¦æ ¼æ›¸å¿…é ˆè¦æ±‚ Coder å°‡ç®—å¼ä¸­çš„ã€Œæ¯ä¸€å€‹ã€æ•¸å­—éƒ½å®šç¾©ç‚ºç¨ç«‹è®Šæ•¸ï¼ˆå¦‚ n1, n2, n3...ï¼‰ï¼Œåš´ç¦åœ¨ q å­—ä¸²ä¸­å‡ºç¾ä»»ä½•ç¡¬ç·¨ç¢¼ï¼ˆHardcodedï¼‰çš„å¸¸æ•¸ã€‚**
"""

def generate_v15_spec(skill_id, model_tag="cloud_pro", architect_model=None):
    """
    [V15.2 Hybrid Architect] 
    1. æ•æ‰ Token æ•¸æ“šã€‚
    2. ä¾ç…§æœ€æ–° Table Schema å­˜å…¥ prompt_content èˆ‡ user_prompt_templateã€‚
    """
    try:
        # 1. æŠ“å–æŠ€èƒ½èˆ‡ RAG æ¯é¡Œ
        skill = SkillInfo.query.filter_by(skill_id=skill_id).first()
        if not skill:
            return {'success': False, 'message': f"Skill {skill_id} not found."}

        # åƒ…å–ç¬¬ 1 ç­†æ¯é¡Œä½œç‚º RAG åƒè€ƒ
        examples = TextbookExample.query.filter_by(skill_id=skill_id).order_by(TextbookExample.id.asc()).limit(1).all()
        rag_block = ""
        if examples:
            rag_block = "\n".join([f"Example: {e.problem_text} (Sol: {e.detailed_solution})" for e in examples])
        else:
            rag_block = "(No textbook examples found. Base design on skill name.)"

        # 2. æ§‹å»ºä½¿ç”¨è€…æŒ‡ä»¤ (é€™å°‡å­˜å…¥ user_prompt_template)
        user_prompt = f"""Skill ID: {skill_id}
Skill Name: {skill.skill_ch_name}

### RAG EXAMPLE (Mother Problem):
{rag_block}

### TASK:
1. åˆ†ææ¯é¡Œæ•¸å­¸çµæ§‹ä¸¦å¯¦ä½œéš¨æ©ŸåŒ–ã€‚
2. åƒ…æä¾› '# [RAG_LOGIC_HERE]' å€å¡Šæ‰€éœ€çš„ Python ä»£ç¢¼ã€‚
"""
        
        full_prompt = V15_1_SYSTEM_PROMPT + "\n\n" + user_prompt

        # 3. å‘¼å« AI ä¸¦æ•æ‰ Token
        client = get_ai_client(role='architect') 
        print(f"   ğŸ§  V15.2 Architect is thinking... (Skill: {skill.skill_ch_name})")
        
        response = client.generate_content(full_prompt)
        spec_content = response.text
        
        # --- [ç§‘ç ”æ•¸æ“šæ•æ‰] ---
        p_tokens = 0
        c_tokens = 0
        if hasattr(response, 'usage_metadata'):
            p_tokens = response.usage_metadata.prompt_token_count
            c_tokens = response.usage_metadata.candidates_token_count

        if not spec_content:
            return {'success': False, 'message': "Empty response from AI."}

        # 4. ä¾ç…§æœ€æ–° Schema å­˜å…¥è³‡æ–™åº«
        # æ›´æ–° SkillInfo ä½œç‚ºå‚™ä»½ (Legacy access)
        skill.gemini_prompt = spec_content
        
        # å»ºç«‹æ–°çš„ Prompt ç´€éŒ„
        new_prompt_entry = SkillGenCodePrompt(
            skill_id=skill_id,
            architect_model=architect_model or "gemini-2.5-flash",
            model_tag=model_tag,
            prompt_type='standard',
            prompt_strategy='single_logic_rag',
            system_prompt=V15_1_SYSTEM_PROMPT, 
            user_prompt_template=user_prompt,      # åŸå§‹è«‹æ±‚æŒ‡ä»¤
            prompt_content=spec_content,           # [MASTER_SPEC] æœ€çµ‚ç”¢å‡º
            creation_prompt_tokens=p_tokens,
            creation_completion_tokens=c_tokens,
            creation_total_tokens=p_tokens + c_tokens,
            version=1,
            is_active=True,
            created_at=datetime.now()
        )
        
        db.session.add(new_prompt_entry)
        db.session.commit()

        return {
            'success': True,
            'version': 15.2,
            'spec': spec_content, 
            'tokens': {'in': p_tokens, 'out': c_tokens},
            'message': "V15.2 Spec generated and logged successfully."
        }

    except Exception as e:
        db.session.rollback()
        return {'success': False, 'message': str(e)}